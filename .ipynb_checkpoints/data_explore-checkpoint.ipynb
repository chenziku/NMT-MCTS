{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"iwsltTokenizedData/combined_train.tsv\", sep=\"\\t\")\n",
    "validate_data = pd.read_csv(\"iwsltTokenizedData/combined_valid.tsv\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"iwsltTokenizedData/combined_test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149135, 2) (6764, 2) (6384, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, validate_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'und diese zwei zusammen zu bringen , erscheint vielleicht wie eine gewal@@ tige aufgabe . aber was ich ihnen zu sagen versuche ist , dass es trotz dieser komplexität einige einfache themen gibt , von denen ich denke , wenn wir diese verstehen , können wir uns wirklich weiter entwickeln .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and bringing those two together might seem a very da@@ un@@ ting task , but what i &apos;m going to try to say is that even in that complexity , there &apos;s some simple the@@ mes that i think , if we understand , we can really move forward .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sentence(sentence):  \n",
    "    new_sentence = []\n",
    "    cur_word = ''\n",
    "    for p in sentence:\n",
    "      if '@@' in p:\n",
    "        cur_word += p[:-2]\n",
    "      else:\n",
    "        if cur_word != '':\n",
    "          new_sentence.append(cur_word+p)\n",
    "          cur_word = ''\n",
    "        elif '&' in p and ';' in p: #this means should be adding this onto last added word \n",
    "          if len(new_sentence) >0:\n",
    "            new_sentence[-1] = new_sentence[-1] + \"'\"+p.split(';')[1]\n",
    "          #OTHERWISE NOT SURE WHAT TO DO\n",
    "          else:\n",
    "            pass #NEED TO IMPLEMENT\n",
    "        else:\n",
    "          new_sentence.append(p)  \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'bringing',\n",
       " 'those',\n",
       " 'two',\n",
       " 'together',\n",
       " 'might',\n",
       " 'seem',\n",
       " 'a',\n",
       " 'very',\n",
       " 'daunting',\n",
       " 'task',\n",
       " ',',\n",
       " 'but',\n",
       " 'what',\n",
       " \"i'm\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'try',\n",
       " 'to',\n",
       " 'say',\n",
       " 'is',\n",
       " 'that',\n",
       " 'even',\n",
       " 'in',\n",
       " 'that',\n",
       " 'complexity',\n",
       " ',',\n",
       " \"there's\",\n",
       " 'some',\n",
       " 'simple',\n",
       " 'themes',\n",
       " 'that',\n",
       " 'i',\n",
       " 'think',\n",
       " ',',\n",
       " 'if',\n",
       " 'we',\n",
       " 'understand',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'really',\n",
       " 'move',\n",
       " 'forward',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_sentence(train_data.iloc[0,1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext import data, datasets\n",
    "\n",
    "global BOS_WORD, EOS_WORD, BLANK_WORD,NUM_WORD\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "\n",
    "def createIterators(batch_size, data_path):\n",
    "\ttokenize = lambda x: x.split(' ') #already have tokenized files so now just split\n",
    "\n",
    "\tSRC = Field(sequential=True, tokenize=tokenize, init_token = BOS_WORD, \n",
    "\t\t\t\t\t\t\t\t\t\teos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\tTGT = Field(sequential=True, tokenize=tokenize, init_token = BOS_WORD, \n",
    "\t\t\t\t\t\t\t\t\t\teos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "\t#MAX_LEN = 30 #start small at max 15 tokens\n",
    "\ttrain,valid,test = TabularDataset.splits(\n",
    "               path=data_path, # the root directory where the data lies\n",
    "               train='combined_train.tsv',\n",
    "               validation='combined_valid.tsv',\n",
    "               test = 'combined_test.tsv',\n",
    "               fields=[('de',SRC),('en',TGT)],\n",
    "               format='TSV',\n",
    "               skip_header=False) \n",
    " \n",
    "\n",
    "\tSRC.build_vocab(train.de)\n",
    "\tTGT.build_vocab(train.en)\n",
    "\n",
    "\tsrc_padding_ind = SRC.vocab.stoi[BLANK_WORD]\n",
    "\ttgt_padding_ind = TGT.vocab.stoi[BLANK_WORD]\n",
    "\ttgt_eos_ind = TGT.vocab.stoi[EOS_WORD]\n",
    "\t#for each token, check if tokenized version of that token is the same (if so then \n",
    "\t#spacy contains that token\n",
    "  #This portion has been tested decently\n",
    "\t\n",
    "\t#docs for Iterator: https://github.com/pytorch/text/blob/c839a7934930819be7e240ea972e4d600966afdc/torchtext/data/iterator.py\n",
    "\ttrain_iter, val_iter, test_iter = data.BucketIterator.splits((train, valid, test), batch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\tsort_key=lambda x: data.interleave_keys(len(x.en), len(x.de)), \n",
    "                    sort_within_batch=True, shuffle=True,repeat=False) #,device=0)\n",
    "\n",
    "\t#NOTE: each batch in train_iter has shape (max numtokens in batch, batch size) but for each batch\n",
    "\t# may have different max num tokens\n",
    "\t'''\n",
    "\t#now trying to print words from iter to see that this makes sense\n",
    "\tfor t in train_iter:\n",
    "\t\ttrgTensor = vars(t)['trg']\n",
    "\t\tprint(trgTensor)\n",
    "\t\tprint([TGT.vocab.itos[i] for i in trgTensor[:,0]])\n",
    "\t\tbreak\n",
    "\t'''\n",
    "\tdatasetDict = {'train_iter':train_iter,'val_iter':val_iter,'test_iter':test_iter,\n",
    "\t\t\t\t\t'SRC':SRC, 'TGT':TGT,'src_padding_ind':src_padding_ind, 'tgt_padding_ind':tgt_padding_ind,\n",
    "\t\t\t\t\t'tgt_eos_ind':tgt_eos_ind}\n",
    "\t\n",
    "\treturn datasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_path = 'iwsltTokenizedData/'\n",
    "dataset_dict = createIterators(batch_size, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6565\n",
      "8713\n",
      "['<unk>', '<blank>', '<s>', '</s>', '.', ',', 'the', 'and', 'to', 'of', 'a', 'that', 'i', 'it', 'in', 'you', 'is', 'we', '&apos;s', 'this', 'so', '&quot;', 'they', 'was', 'for', 'are', 'on', 'have', 'what', 'but', '?', '--', 'can', 'with', '&apos;t', 'there', 'about', 'be', 'at', 'as', 'all', 'do', 'not', 'one', 'my', '&apos;re', 'an', 'people', 'like', 'now']\n",
      "6565\n",
      "149184\n",
      "6784\n",
      "6400\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_dict['TGT'].vocab.itos))\n",
    "print(len(dataset_dict['SRC'].vocab.itos))\n",
    "allStrings = [k.lower() for k in dataset_dict['TGT'].vocab.stoi.keys()]\n",
    "print(allStrings[:50])\n",
    "print(len(set(allStrings)))\n",
    "print(len(dataset_dict['train_iter'])*64)\n",
    "print(len(dataset_dict['val_iter'])*64)\n",
    "print(len(dataset_dict['test_iter'])*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class MainParams:\n",
    "    def __init__(self, dropout, src_vocab_size, tgt_vocab_size, batch_size):\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.model_params = dict(d_model=128,nhead=8,num_encoder_layers=4, num_decoder_layers=4,\n",
    "                dim_feedforward=512, dropout=0.2,activation='relu',src_vocab_size=src_vocab_size,\n",
    "                tgt_vocab_size=tgt_vocab_size)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_decode_steps = 60 #MAX NUMBER OF DECODING STEPS WE'LL do (can increase this)\n",
    "        \n",
    "src_vocab_size = len(dataset_dict['SRC'].vocab.itos)\n",
    "tgt_vocab_size = len(dataset_dict['TGT'].vocab.itos)\n",
    "main_params = MainParams(dropout=0.2,src_vocab_size=src_vocab_size,\n",
    "              tgt_vocab_size=tgt_vocab_size,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-11756e2e1313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'value_supervised_small.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GitHub/Learning-to-Search/transformer_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, activation, src_vocab_size, tgt_vocab_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 dim_feedforward,dropout,activation,src_vocab_size,tgt_vocab_size):\n\u001b[1;32m     13\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, max_len=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mencoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_feedforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mencoder_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GitHub/Learning-to-Search/transformer_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, max_len)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from transformer_model import TransformerModel\n",
    "\n",
    "path = 'savedModel/'\n",
    "path_to_policy = path + 'policy_supervised_small.pt'\n",
    "path_to_value = path + 'value_supervised_small.pt'\n",
    "\n",
    "policy = TransformerModel(**(main_params.model_params)).to(main_params.device).double()\n",
    "policy.load_state_dict(torch.load(path_to_policy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
